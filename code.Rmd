---
title: "Etude des violences sexuellles par département en France"
author: "Bill Yehouenou, Jeanne Ropert"
date: "2023-01-19"
output: 
  pdf_document:
    latex_engine: xelatex
    keep_tex: true
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA)
library(readxl)
library(glmnet)
library(kableExtra)
library(ggplot2)
library(corrplot)
library(lmtest)
library(sandwich)
library(car)
library(tidyverse)
library(cowplot)
library(stargazer)
library(ISLR)
library(lattice)
library(pls)
library(caret)
```

\newpage

# Problématique

Les violences sexuelles se définissent comme « _toute atteinte sexuelle commise sans le consentement d’une personne ou tout agissement discriminatoire fondé sur le sexe_ ».
L’évolution des mentalités et de la loi a permis ces dernières années, une libération de la parole. En effet, le nombre de violences sexuelles recensées est en hausse de 33% en 2021. De plus, selon une enquête publiée en 2021 par l’INSERM, « __14,5 % des femmes et 6,4 % des hommes en France, soit environ 5,5 millions de personnes, auraient été confrontés avant l’âge de 18 ans à des violences sexuelles__ ». Cette dernière nous apprend également que ces violences apparaissent dans la majeure partie des cas dans un cadre familial.
Nous nous sommes questionnées sur les facteurs qui pourraient influencer le nombre de violences sexuelles, en analysant les violences sexuelles physiques par département de France métropolitaine en 2018. En effet, __comment expliquer les différences du nombre de faits de violences sexuelles entre les départements ?__. Ainsi, l'équation de notre modèle devrait se présenter comme suit :

$$ Faits=b_0+b_1*Mediane.revenu+b_2*Pop+b_3*Homme.sans.diplome+b_4*Femme.sans.diplome+$$
$$ b_5*Taux.chomage+b_6*Taux.pauvrete+b_7*Taux.logements.sociaux+b_8*Sexe.politique+b_9*Geographie+e $$
```{r importation des donnees,include=FALSE,message=FALSE}
data <- read_csv("data1.csv")
data$Faits <- (data$Faits*1000)/data$Pop # transformation des faits en taux pour 1000

data_reg <- data[,3:12] # retrait des variables qualitatives
data_reg$Sexe_politique <- as.factor(data_reg$Sexe_politique)
data_reg$Geographie <- as.factor(data_reg$Geographie)

data_reg <- dplyr::select(data_reg, -3) 
head(data_reg, 3)
```

# Collecte des données

Pour commencer notre étude, nous avons constitué notre base de données, pour cela nous avons sélectionné neuf variables explicatives et une variable à expliquer. Notre variable endogène est donc le _nombre de faits de violences sexuelles physiques par département_. 

Concernant, nos variables exogènes, nous nous sommes d'abord intéressées au niveau de vie des départements. Pour cela, nous avons réuni des données concernant _le revenu médian disponible en euros_, _le taux de pauvrete_, _le taux de chômage_ et _le taux de logements sociaux_. Également, nous avons voulu faire intervenir quelques caractéristiques sur la population, comme son nombre ou encore les effectifs des hommes et femmes de plus de 25 ans sans diplômes. Pour finir, nous nous sommes penchées sur deux caractéristiques des départements, notamment _la situation géographique_, codée 0 pour le nord et 1 pour le sud, et _le sexe du président du conseil départemental_, codé 0 pour les hommes et 1 pour les femmes. Nous avons recueilli ces données concernant 96 départements sur le site du gouvernement, de l’Insee et de l’observatoire des territoires.

```{r dictionnaire des variables, echo=FALSE, warning=FALSE}
#creation du dictionnaire des variables
code <- colnames(data_reg)
def <- c("Nombre de faits de violences pour 1000",
         "Mediane du revenu disponible",
         "Population totale du département",
         "Effectif des hommes sans diplome",
         "Effectif des femmes sans diplome",
         "Taux de chômage en %",
         "Taux de pauvrete en %",
         "Taux de logements sociaux en %",
         "Sexe personalité politique",
         "Situation géographie"
         )
nature <- c("Quantitative","Quantitative","Quantitative","Quantitative",
            "Quantitative","Quantitative","Quantitative","Quantitative",
            "Indicatrice","Indicatrice")
sig <- c("","+","+","+","+","+","+","+","+/- selon le cas","+/- selon le cas")
dict <- as.data.frame(matrix(c(code,def,nature,sig),10,4))
colnames(dict) <- c("Code","Définition","Nature","Signe attendu")
# affichage du tableau précédemment défini
#kable(dict,format="latex", booktabs = T, caption = "Dictionnaire des variables")%>%
 # kable_styling(latex_options = "striped")
tibble(dict)
```


# Partie 1 : Etude de l'hétéroscédasticité

## Statistiques descriptives univariées

Pour en apprendre davantage sur notre variable d'intérêt, nous allons procéder à une analyse statistique desctriptive. La boîte à moustache de notre variable d'intérêt représente une __variabilité assez faible__ mais avec des valeurs atypiques notables.

```{r variable interet, fig.width=12,fig.height=6, echo=FALSE,message=FALSE}
gf_histfacts <- ggplot(data_reg, aes(y=Faits)) + 
  geom_boxplot(fill="slateblue", alpha=.6) + 
  ggtitle("Boxplot du nombre de faits pour 1000")

gf_statfacts <- ggplot(data_reg, aes(y=Faits))+
  geom_histogram(fill="darkseagreen",color="#e9ecef", bins=20)+
  ggtitle("Histogramme du nombre de faits pour 1000")
#mettre tous les graphes dans une grille
plot_grid(gf_histfacts,gf_statfacts + coord_flip(), ncol = 2)
```

L'analyse de l'histogramme du nombre de faits montre que les observations sont assez concentrées entre 0 et 1 fait pour 1000 habitant. Toutefois, elle possède quelques outliers qu'il faudra surveiller. 
Nous avons décidé de nous intéresser à la variable _taux de logements sociaux_ qui, d'àprès notre revue de littérature, est une variable assez importante.

```{r histogramme logement,fig.width=12,fig.height=6, echo=FALSE,message=FALSE}
ggplot(data_reg, aes(x=Taux_logements_sociaux)) + 
  geom_histogram(bins=20, fill="cornflowerblue", color="#e9ecef") +
  ggtitle("Histogramme du taux de logements sociaux")+
  theme(plot.title = element_text(hjust = 0.5))+
  ylab("Effectifs")+
  xlab("Taux de logements sociaux")
```

L'histogramme du _taux de logements sociaux_ révèle des valeurs atypiques. De plus, on constate que plusieurs départements sont en dessous du quota de logements sociaux prévus en France, soit 10%. En termes de distribution, la variable du _taux de logement sociaux_, sa distribution semble asymétrique ce qui peut présenter un problème pour notre modèle.

## Statistiques descriptives bivariées

Pour en apprendre davantage sur le type de lien qui existe entre notre variable endogène et nos variables exogènes, nous utilisons la représentation graphique en nuage de points.
Tout d’abord, comme nous le montre les graphiques ci-dessous, la médiane du revenu disponible, le taux de pauvrete et le nombre d’hommes et femmes sans diplômes sont négativement et linéairement corrélés à notre variable endogène, c’est-à-dire le nombre de violences sexuelles.

```{r analyse bivariee,fig.width=13, fig.height=13, echo=FALSE, message=FALSE}
gf_factsmed <- ggplot(data_reg)+aes(x=log(Mediane_revenu_dispo), y=Faits) +
  geom_point(color = "red3") + xlab("Mediane revenu disponible")+
  geom_smooth(method = "loess", color = "black")+
  theme(plot.title = element_text(hjust = 0.5))+
  theme_minimal()+
  ggtitle("Graphe des violences par le revenu médian")
  
gf_factpop <- ggplot(data_reg,aes(x=Taux_pauvrete, y=Faits)) +
  geom_point(color = "blue3") + xlab("Taux de pauvrete")+
  geom_smooth(method = "loess", color = "black")+
  theme(plot.title = element_text(hjust = 0.5))+
  theme_minimal()+
  ggtitle("Graphe des violences par niveau de pauvreté")

gf_factsmen <- ggplot(data_reg,aes(x=Homme_sans_diplome, y=Faits)) +
  geom_point(color = "red3") + xlab("Hommes sans diplômes")+
  geom_smooth(method = "loess", color = "black")+
  theme(plot.title = element_text(hjust = 0.5))+
  theme_minimal()+
  ggtitle("Graphe des violences par niveau d'éducation masculine")
 
gf_factswom <- ggplot(data_reg,aes(x=log(Femme_sans_diplome), y=Faits)) +
  geom_point(color = "blue3") + xlab("Femmes sans diplômes") +
  geom_smooth(method = "loess", color = "black")+
  theme(plot.title = element_text(hjust = 0.5))+
  theme_minimal()+
  ggtitle("Graphes des violences par niveau d'éducation féminine")

plot_grid(gf_factsmed,gf_factpop,gf_factsmen,gf_factswom, nrow = 2)
```

Ainsi, cette première partie nous a permis de visualiser l’ensemble de notre base de données, de constater les éventuels problèmes, les corrélations et le type de lien entre les variables. Cette étape est nécessaire pour poursuivre au mieux la réalisation du modèle économétrique.

## Matrice de corrélation

Désormais, nous allons procéder à une analyse statistique descriptive bivariée afin d’étudier les relations entre le nombre de violences sexuelles recensées par département et nos variables explicatives, mais également les possibles liens entre nos variables explicatives elles-mêmes.

```{r matrice de correlation, echo=FALSE}
corr_matrice <- cor(data_reg[,1:7])
# Créer une palette de couleurs
col_palette <- colorRampPalette(c("red3","tomato","cornflowerblue","blue2"))(4)
# Créer le graphique de heatmap
corrplot::corrplot(corr_matrice, type = "upper", order = "hclust", col = col_palette,
         tl.col = "black", tl.srt = 45, tl.cex = 0.8)
```

De notre côté, les faits de violences sexuelles sont fortement corrélés au nombre de femmes et d’hommes de plus de 25 ans sans diplômes, et plus légèrement corrélés à la médiane du revenu disponible et au taux de logements sociaux. Par ailleurs, cette matrice met en évidence des corrélations entre des variables explicatives. En effet, les variables Homme et Femme sans diplômes ou encore Revenu disponible et Taux de pauvreté sont corrélées entre elles. Une présence de colinéarité entre des variables explicatives peut altérer notre modèle, un choix devra donc être fait au moment de la régression.

## Modèle
### Spécification du modèle

Afin d’estimer le nombre de faits de violences sexuelles par département, nous devons mettre en place un modèle économétrique constitué des variables qui pourraient expliquer ces violences. Pour choisir le modèle qui estimera le mieux les violences sexuelles, nous commençons par effectuer une régression linéaire du nombre de faits par département, en fonction des neuf autres variables

```{r specification du modele, warning=FALSE,comment=NA,echo=FALSE}
model1 <- lm(Faits~., data=data_reg)
model2 <- lm(Faits~Mediane_revenu_dispo+Taux_chomage+
               Taux_pauvrete+Taux_logements_sociaux, data=data_reg)
model3 <- lm(Faits~Taux_chomage+Taux_pauvrete+Geographie+
               Taux_logements_sociaux, data=data_reg)
stargazer(model1,model2,model3, type="text")
```

Après avoir mis en route et comparé différents modèles, nous avons retenu un modèle (1) avec toutes les variables. En effet, il s'agit du modèle avec le meilleur R2 ajusté. Il faudra faire un test de Ramsey pour vérifier la spécification du modèle. 

### Test de Ramsey

```{r reset test, warning=FALSE, echo=FALSE, comment=NA}
resettest(model1)
```

La p-value du test de Ramsey est inférieure au seuil de 5% alors, le modèle est bien spécifié.

## Analyse des résidus du modèle

### Résidus studentisés

Les résidus studentisés obtenus par validation croisée nous montrent que les départements cités ci-dessous sont des départements atypiques dans notre base de données.

```{r, echo=FALSE}
rstud <- rstudent(model1)
data$Departement[which(abs(rstud) >= 2)]
```

On a procédé aussi à un lissage de nos résidus et ce lissage est assez proche de 0. Donc, on soupçonne que nos résidus ont une espérance nulle et de variance constante.

```{r residus studentisees, echo=FALSE, fig.width=12, fig.height=6, message=FALSE, warning=FALSE, comment=NA}
ggplot(as.data.frame(rstud),aes(1:length(rstud),rstud))+
  geom_point(cex=.5,pch=10)+
  xlab("")+ylab("Résudus studentisées")+
  geom_hline(yintercept=qt(0.025,1004), linetype="dashed", color = "coral1")+
  geom_hline(yintercept=qt(0.975,1004), linetype="dashed", color = "coral1")+
  geom_smooth(method = "loess",color="purple")+
  ggtitle("Analyse graphique des résidus studentisées")+
  theme_minimal()
```

### Test de normalité des résidus de Shapiro-Wilk

```{r normalite des residus,comment=NA, echo=FALSE}
shapiro.test(model1$residuals)
```

La p-value du test de normalité des résidus est inférieure au seuil de 5% alors on rejette l'hypothèse de normalité des résidus. Les résidus ne suivent pas une loi normale. Cela est dû à l'existence de valeurs atypiques qui étendent la distribution.

```{r graphique de normalite, echo=FALSE, fig.height=6, fig.width=12, message=FALSE, warning=FALSE}
# densité des résidus du modèle
gf_dens <- ggplot(as.data.frame(model1$residuals), aes(x=model1$residuals)) + 
  geom_density(fill="cornflowerblue", color="azure", alpha=0.8)+xlab("Residus")+
  ggtitle("Densité des résidus du modèle")
# histogramme des résidus
gf_hist <- ggplot(as.data.frame(model1$residuals), aes(x=model1$residuals)) + 
  geom_histogram(fill="tomato", color="azure", alpha=0.8)+xlab("Residus")+
  ggtitle("Histogramme des résidus")

plot_grid(gf_dens,gf_hist,ncol = 2)
```

### Test d'hétéroscédasticité

```{r test heteroscedasticite,comment=NA, echo=FALSE}
bptest(model1)
```

La p-value est inférieure au seuil de 5% alors on rejette l'hypothèse nulle d'homoscédasticité. Donc, on est en présence d'un problème d'hétéroscédasticité des résidus. Il faut donc appliquer la correction de White.

## Correction de White

```{r test white,comment=NA, echo=FALSE}
coeftest(model1,vcovHC(model1))
```

Après la mise en oeuvre de la méthode, on remarque que le niveau de significativité des coefficients a diminué car le modèle a été corrigée de l'hétéroscédasticité. Toutefois, les variables significatives demeurent toujours significatives au seuil de 5%.

# Partie 2 : Analyse de la multicolinéarité

## Détection de la multicolinéarité

Afin de confimer nos soupçons concernant l'existence de multicolinéarité au sein de notre modèle final, nous regardons les facteurs d’inflation de la variance (VIF).

```{r calcul du vif,echo=FALSE}
vif(model1)
```

Le __VIF__ calcule la colinéarité d’une variable en fonction des autres régresseurs. La valeur au-dessus duquel nous considérons qu’il y a de la multicolinéarité n’est pas fixe, nous prendrons donc **5** comme valeur de reférence. On est donc en présence de multicolinéarité pour les variables `Homme` et `Femme` sans diplôme. 

## Méthodes de réduction de dimension

## Partitionnement des données

Nous construirons notre modèle sur les données d'entraînement et évaluerons ses performances sur les données de test. Il s'agit d'une approche de *validation de hold-out* pour évaluer la performance du modèle. Notre échantillon d'apprentissage contient 70 % des données tandis que l'échantillon test contient les 30 % restants.

```{r data partitionning, echo=FALSE}
set.seed(100) 
index = sample(1:nrow(data_reg), 0.7*nrow(data_reg)) 
 # echantillon d'apprentissage et echantillon test
dapp = data_reg[index,]
dtest = data_reg[-index,]

dim(dapp);dim(dtest)
```

```{r function metrics, include=FALSE}
# on cree une fonction pour afficher la RMSE et le R2 de chaque méthode
eval_metrics = function(model, df, predictions, target){
    resids = df[,target] - predictions
    resids2 = resids**2
    N = length(predictions)
    r2 = as.character(round(summary(model)$r.squared, 2))
    adj_r2 = as.character(round(summary(model)$adj.r.squared, 2)) 
    cat("R carre ajusté:",adj_r2, "et") # Adjusted R-squared   
    cat(" RMSE:", as.character(round(sqrt(sum(resids2)/N), 2))) # RMSE
}
```

## Regression sur Composantes principales

```{r pcr,echo=FALSE}
set.seed(9)
# expliquer le nombre de faits en fonction des autres variables
model.pcr <- pcr(Faits~., data=data_reg, scale=TRUE, jackknife = TRUE, 
               validation="CV", ncomp=ncol(data_reg)-1)
# affiche la description de l'analyse en composantes principales
summary(model.pcr)
#eval_metrics(model.pcr, data_reg, Faits, dtest)
```

Après analyse des sorties du modèle PLS, on peut conclure que le modèle explique environ *57,6%* de la variance de la variable dépendante *Faits* en utilisant 8 composantes. Le modèle a été validé à l'aide de la RMSEP avec une validation croisée à 10 segments aléatoires et le modèle avec **7 composantes** présente la meilleure performance avec une valeur de 0.001075 pour CV et 0.001071 pour adjCV.

```{r pcr validation plot, fig.height=5, fig.width=12, echo=FALSE}
par(mfrow=c(1,2))
validationplot(model.pcr,legendpos="topright")
validationplot(model.pcr, val.type="MSEP",legendpos= "topright")
# validationplot(model.pcr, val.type="R2")
```

```{r, fig.height=5, fig.width=12, echo=F}
# on choisit 6 composantes
plot(model.pcr, ncomp=6, line=TRUE, pch=19, cex=.4) # bonne regression
```


Les modèles avec plus de composantes peuvent potentiellement présenter une sur-ajustement, c'est-à-dire qu'ils peuvent être trop complexes pour les données disponibles, ce qui peut entraîner des prédictions moins précises sur de nouveaux ensembles de données.

```{r coefs estimated,echo=FALSE,warning=FALSE}
#coefficients(model.pcr, ncomp=6)
coefplot(model.pcr, ncomp=6, se.whiskers = TRUE, labels = prednames(model.pcr), cex.axis = 0.5)
```

Les coefficients pour les variables *Mediane_revenu_dispo*, *Homme_sans_diplome*, *Femme_sans_diplome* et *Taux_chomage*,  sont tous négatifs, ce qui suggère que des valeurs plus élevées de ces variables sont associées à des valeurs plus faibles du nombre de faits de viloences signalées. De même, le coefficient positif pour la variable *Taux_logements_sociaux* et *Taux_pauvrete* suggère une association positive avec la variable dépendante.

Toutefois, ces coefficients ne réfletent pas l'effet direct de chaque variable sur le nombre de faits de violences conjugales.

## Moindres carrés partiels

```{r pls,echo=FALSE}
set.seed(98)
# expliquer la variable "Faitsa en fonction des autres variables 
pls_est <- plsr(Faits~., data=data_reg, scale=TRUE, jackknife = TRUE, validation="CV", ncomp=8)
summary(pls_est)
```

On peut voir que l'erreur diminue au fur et à mesure que le nombre de composantes augmente, mais le taux de décroissance ralentit à partir de 5 ou 6 composantes. La meilleure performance est atteinte avec 6 composantes, où l'erreur de validation croisée est de 0.001156.

```{r pls cross validation plot, echo=FALSE}
validationplot(pls_est,legendpos= "topright")
#validationplot(pls_est, val.type="R2")
```


```{r estimation des coefs,eval=FALSE,echo=FALSE}
#coefficients(pls_est, ncomp=8) 
coefplot(pls_est, ncomp=8, se.whiskers = TRUE, labels = prednames(pls_est), cex.axis = 0.5)
```

En ce qui concerne l'interprétation des coefficients, chaque coefficient représente uniquement la relation entre la variable explicative et celle de réponse. Par exemple, un coefficient négatif pour la variable *Homme_sans_diplome* indique une relation inverse entre cette variable et la variable de réponse, c'est-à-dire que les régions avec un taux plus élevé d'hommes sans diplôme ont tendance à avoir une valeur plus faible pour le nombre de faits de violences conjuguales signalées. De même, un coefficient positif pour la variable *Taux_pauvrete* indique une relation directe entre cette variable et la variable de réponse, c'est-à-dire que les régions avec un taux plus élevé de pauvreté ont tendance à avoir une valeur plus élevée pour le nombre de faits de violences conjuguales signalées.

## Méthodes pénalisées

Les méthode de pénalisation sont des techniques pour régulariser notre modèle linéaire et réduire le risque de surajustement (overfitting).

## Régression Ridge

```{r ridge, echo=FALSE}
don <- data_reg |> mutate(Geographie = as.numeric(Geographie), 
                              Sexe_politique = as.numeric(Sexe_politique))
# creation des matrices Y et X
Y <- as.matrix(don[, c("Faits")]) # variable d'intérêt
X <- as.matrix(don[, colnames(don)[-1]])

# construction du modèle "Ridge"
#glmridge <- glmnet(X,Y, family = "gaussian", alpha = 0)

# détermination de lambda par validation croisée
set.seed(231)
cv.ridge <- cv.glmnet(X, Y, family ="gaussian", alpha =0, type.measure="mse")
plot(cv.ridge)

# choix du meilleur lambda
bestlam<- cv.ridge$lambda.min
print(bestlam)

```

On constate que la valeur du meilleur paramètre lambda qui minimise l'erreur quadratique moyenne estimée par validation croisée est **9.116526e-05**.

```{r coefficients of the model, echo=FALSE}
best_model <- glmnet(X, Y, alpha = 0, lambda = bestlam)
coef(best_model)
```

On conclue ici qu'un coefficient négatif indique une *relation inverse* avec la variable dépendante, tandis qu'un coefficient positif indique une *relation directe* avec la variable dépendante.
Plus la valeur absolue d'un coefficient est élevée, plus grande est l'importance de la variable correspondante pour la prédiction de la variable dépendante.
On constate qu'en raison de l'utilisation de la régularisation dans le modèle de Ridge, certains de nos coefficients sont très petits (*Homme_sans_diplome* et *Femme_sans_diplome*) par rapport à d'autres. Cela est dû à la pénalisation de la magnitude des coefficients qui est utilisée pour éviter le **surajustement** et améliorer le modèle.

```{r previsions and rsquare, echo=FALSE}
# previsions
y.pred <- predict(best_model, newx=X, s= bestlam, type = "response")

# qualité ajustement R2
SST <- sum((Y-mean(Y))^2)
SSE <- sum((y.pred - Y)^2)
rsquare_ridge <- 1 - SSE/SST
rsquare_ridge

rmse_ridge <- sqrt(SSE)
```

Le R-carré s'avère être de 0.5660313. C'est-à-dire que le meilleur modèle a été en mesure d'expliquer 56.6% de la variation des valeurs de réponse des données d'entraînement.

## Regression Lasso-Hitters

```{r lasso, echo=FALSE}
###transformation des variables type facteurs en variables numériques 
data_reg$Sexe_politique <- as.numeric(data_reg$Sexe_politique)
data_reg$Geographie <- as.numeric(data_reg$Geographie)

Y<- as.matrix(data_reg[, c("Faits")])
X<- as.matrix(data_reg[,c("Mediane_revenu_dispo","Homme_sans_diplome","Femme_sans_diplome","Taux_chomage","Taux_pauvrete","Taux_logements_sociaux","Sexe_politique","Geographie")])

# détermination de lambda par validation croisée
set.seed(231)
cv.lasso <- cv.glmnet(X, Y, family ="gaussian", alpha =1, type.measure="mse")
plot(cv.lasso)

#choisit la valeur de lambda qui minimise l'erreur quadratique moyenne estimée par validation croisée
bestlam2 <- cv.lasso$lambda.min
print(bestlam2)

```
On constate que la valeur du paramètre lambda qui minimise l'erreur quadratique moyenne estimée par validation croisée est **4.537317e-06**.

```{r, echo=FALSE}
best_model2 <- glmnet(X,Y, alpha = 1, lambda = bestlam2) 
coef(best_model2)
```

On remarque qu'avec l'utilisation d'une régression de Lasso Hitters, certains de nos coefficients sont très petits (*Mediane_revenu_dispo* et *Homme_sans_diplome*) par rapport à d'autres. La variable *Femme_sans_diplome* a quant à elle été retirée du modèle. Encore une fois, cela est dû à la pénalisation de la magnitude des coefficients qui est utilisée pour éviter le **surajustement** et améliorer le modèle.


```{r previsions lasso, echo=FALSE}
####previsions 
y.pred <- predict(best_model2, newx=X, s= bestlam, type = "response")

###qualité ajustement
SST <- sum((Y-mean(Y))^2)
SSE <- sum((y.pred - Y)^2)
rsquare_lasso <- 1 - SSE/SST
rsquare_lasso

rmse_lasso <- sqrt(SSE)
```

Le R-carré vaut 0.5750197. C'est-à-dire que le meilleur modèle a été en mesure d'expliquer 57.5% de la variation des valeurs de réponse des données d'entraînement.

Ainsi, la régression de Lasso Hitters apparaît être plus performante et proposer un meilleur modèle que la régression Ridge. 


## Régression Elastic Net

La régression Elastic Net combine deux formes de pénalisation, Ridge et Lasso.

```{r train_test, include=FALSE}
set.seed(123)
train.samples <- data_reg$Faits %>% createDataPartition(p=0.5, list = FALSE)
train.data <- data_reg[train.samples,]
test.data <-  data_reg[- train.samples,]
```

```{r elasticnet, include=FALSE}

custom <- trainControl(method = "repeatedcv",
                       number = 10,
                       repeats = 5,
                       verboseIter = TRUE)

set.seed(1234)
elasticnet <- train(Faits~.,
            train.data,
            method='glmnet',
            tuneGrid =expand.grid(alpha=seq(0,1,length=10),
                                  lambda = seq(0,10,length=10)),
            trControl=custom)

```

```{r,echo=FALSE}
elasticnet$bestTune
```

On remarque que les meilleurs alpha et lambda estimés sur les données d'entrainement sont équivalents à 0. 

```{r, echo=FALSE}
coef(elasticnet$finalModel, elasticnet$bestTune$lambda)
```

Avec l'application d'une régression Elastic Net, toutes les variables sont conservées dans le modèle final. Cependant, les variables *Mediane_revenu_dispo*, *Femme_sans_diplome* et *Homme_sans_diplome* ont des coefficients plus petits que les autres variables. 

```{r prediction elasticnet, echo=FALSE}
# Make predictions
predictions <- elasticnet %>% predict(test.data)

# Model prediction performance
RMSE_elastic = RMSE(predictions, test.data$Faits)
Rsquare_elastic = R2(predictions, test.data$Faits)
Rsquare_elastic
```

Le R-carré vaut 0.5985996. Donc le meilleur modèle a été en mesure d'expliquer 59.8% de la variation des valeurs de réponse des données d'entraînement.


## Choix du modèle 

Afin de sélectionner le meilleur modèle nous étudions le tableau récapitulatif suivant :

```{r, echo=FALSE, fig.width=12}
vec_rsquare <- c("56.96","57.11",round(rsquare_ridge*100,2),round(rsquare_lasso*100,2),round(Rsquare_elastic*100,2))
vec_rmse <- c("0.0010","0.0011",round(rmse_ridge,5),round(rmse_lasso,5),round(RMSE_elastic,5))
nom_regression <- c("Composantes principales","Moindres carrés Partiels","Ridge","Lasso","Elastic Net")
table_result <- tibble(nom_regression,vec_rsquare,vec_rmse)
names(table_result) = c("Test","Rsquare","RMSE")
tibble(table_result)
#kable(table_result,format="latex", booktabs = T, caption = "Comparaion des différentes regressions")%>%
 # kable_styling(latex_options = "striped")
```

Au vu des différents indiateurs, Elastic net apparaît être la meilleure régression car son R-squared est le plus grand et sa RSME est minimisée.
Son R-squared est aussi supérieur à celui de notre modèle initial, ainsi, le modèle final conservé est celui produit par la régression Elastic Net.

\newpage

# Partie 3 : Analyse de l'endogénéité

L'endogénéité survient lorsqu'une variable explicative (endogène) est corrélée avec les erreurs de régression. Cela peut entraîner des biais dans les estimations des paramètres du modèle et rendre difficiles l'interprétation et la validité des résultats obtenus. Il existe trois sources d'endogénéité : 

* *les variables omises,* 
* *les erreurs de mesure,* 
* *la simultanéité*

Plusieurs approches peuvent être utilisées pour traiter l'endogénéité dans un modèle économétrique dont celle des variables instrumentales et des modèles à équations simultanées. 

Les variables instrumentales sont des variables qui sont corrélées avec la variable endogène, mais qui ne sont pas corrélées avec les erreurs de régression. Elles sont utilisées pour estimer les paramètres du modèle en remplaçant la variable endogène problématique par ses valeurs prédites à partir des variables instrumentales. Cela permet de supprimer les biais potentiels dus à l'endogénéité. Avec les modèles à équations simultanées, les variables endogènes sont modélisées simultanément plutôt que séparément, ce qui permet de prendre en compte les interactions entre elles et de capturer les relations de causalité simultanée. Dans notre cas, les équations sont difficiles à identifier, la méthode des variables instrumentales serait donc plus adaptée afin de résoudre l'endogénéité qui pourrait être due aux variables omises. 

Enfin, nous nous sommes questionnés sur les variables omises qui pourraient être ajoutées à notre modèle.
Premièrement, les facteurs culturels ne sont pas présents dans nos variables. Une variable sur la religion aurait pu être pertinente et révéler des différences sur le nombre de faits, en fonction des proportions de chaque religion au sein des départements français. Deuxièmement, d'autres facteurs individuels seraient appropriés à notre étude tels que : 

* la santé mentale des individus : les victimes de violences sexuelles peuvent avoir besoin d'un soutien psychologique pour faire face aux traumatismes, mais l'accès à des services de santé mentale peut varier en fonction du lieu de résidence, du niveau de revenu ou de l'assurance maladie)
* les antécédents de violences sexuelles : les personnes ayant été victimes de violences auparavant peuvent être plus susceptibles d'être victimes à nouveau. Cependant, tout comme le recensement des faits de violences sexuelles, les antécédents sont très difficiles à évaluer pour chaque département. 

Nous avons réfléchi aux éventuels erreurs de mesure qui causées des biais dans notre estimation comme l'erreur de mesure des violences sexuelles. En effet, certaines personnes peuvent ne pas être conscientes qu'elles ont été victimes de violences sexuelles ou peuvent hésiter à signaler des cas de violences sexuelles.

\newpage

# Conclusion

Pour conclure, dans cette étude sur les violences sexuelles, nous avons d’abord analysé notre base de données de façon univariée et bivariée afin d’orienter au mieux la suite de notre réflexion. Après-coup, nous avons sélectionné notre modèle économétrique, pour cela, nous avons testé différents modèles. Après avoir vérifier la spécification du modèle, nous avons retenu le meilleur modèle qui est celui ayant validé les test d'abscence d'autocorrélation, d’hétéroscédasticité. La présence d'une hétéroscédasticité nous a conduit à mettre en ouvre un modèle à correction d'erreur (MCE).
Ce modèle présentait néanmoins des problèmes de multicolinéarité. Pour cela, nous avons appliqué des méthodes de réduction de dimension et de pénalisation. Parmi ceux ci, le modèle optimal est celui proposé par *elastic net*. Ce modèle est défini par :

$$ Faits=6.72e-03 -2.4e-07*Mediane.revenu-2.26e-08*Homme.sans.diplome-1.15e-08*Femme.sans.diplome $$
$$ -3.76e-04*Taux.chomage+1.57e-04*Taux.pauvrete+5.07e-05*Taux.logements.sociaux+$$
$$8.34e-04*Sexe.politique+5.24e-04*Geographie+e $$

Enfin, nous avons discuté des potentiels sources d'edogénéité qui pourraient exister dans notre modèle. La source prédominante d'endogénéité serait l'omission des variables `antécédents des violences familiales` et la `santé mentale`. Notre étude pourrait être poursuite en appliquant la méthode des variables instrumentales dans un modèle des Doubles Moindres Carrés (DMC).

\newpage

# Bibliographie

## Données

1. [Nombre de faits de violences sexuelles physiques par département](https://www.data.gouv.fr/fr/datasets/bases-communale-et-departementale-des-principaux-indicateurs-des-crimes-et-delits-enregistres-par-la-police-et-la-gendarmerie-nationales/)

2. [Revenu médian disponible en euros](https://www.observatoire-des-territoires.gouv.fr/mediane-du-revenu-disponible-par-uc)

3. [Population](https://www.data.gouv.fr/fr/datasets/bases-communale-et-departementale-des-principaux-indicateurs-des-crimes-et-delits-enregistres-par-la-police-et-la-gendarmerie-nationales/)

4. [Homme sans diplôme](https://www.insee.fr/fr/statistiques/1893149)

5. [Femme sans diplôme](https://www.insee.fr/fr/statistiques/1893149)

6. [Taux de pauvreté, taux de chômage, taux de logements sociaux](https://www.data.gouv.fr/fr/datasets/logements-et-logements-sociaux-dans-les-departements-1/)

7. [Situation géographique](http://www.cartesfrance.fr/carte-france-departement/carte-france-departements.html)

8. [Sexe du président du conseil départemental](https://www.regions-departements-france.fr/pdf/departements/liste-des-presidents-de-departement-2020.pdf)

\newpage

# Annexe

Contribution au projet 

**Bill** : Tout le projet sauf les régressions de Lasso et Elastic Net.

**Jeanne** : Tout le projet sauf les régressions des Moindres Carrés Partiels, des Composantes Principales et de Ridge.
